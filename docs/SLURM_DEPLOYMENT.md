# ğŸš€ Deployment do Worker SLURM Containerizado

Este documento descreve como fazer o deployment do worker SLURM containerizado em produÃ§Ã£o.

## âœ… Status da ImplementaÃ§Ã£o

### âœ… Implementado e Testado
- Container SLURM com cliente SLURM instalado
- Script de inicializaÃ§Ã£o funcional
- IntegraÃ§Ã£o com docker-compose
- Carregamento correto das tarefas SLURM
- Conectividade com RabbitMQ
- Ambiente Python/Conda funcionando

### ğŸ”„ Para ConfiguraÃ§Ã£o em ProduÃ§Ã£o
- ConfiguraÃ§Ã£o SLURM do cluster de produÃ§Ã£o
- Volumes e permissÃµes especÃ­ficos do ambiente
- VariÃ¡veis de ambiente do cluster

## ğŸ“‹ PrÃ©-requisitos para ProduÃ§Ã£o

1. **Host com acesso ao cluster SLURM**
   - ConfiguraÃ§Ã£o SLURM em `/etc/slurm/`
   - Conectividade de rede com controladores SLURM
   - UsuÃ¡rio com permissÃµes para submeter jobs

2. **Volumes necessÃ¡rios**
   ```bash
   /etc/slurm        # ConfiguraÃ§Ãµes SLURM (read-only)
   /var/spool/slurm  # Spool directory (read-write)
   ```

## ğŸš€ Deployment Passo a Passo

### 1. Preparar Ambiente

```bash
# Clone do repositÃ³rio
git clone <repository-url>
cd orchestration

# Configurar variÃ¡veis de ambiente
cp .env.slurm.example .env.slurm
# Editar .env.slurm conforme seu ambiente
```

### 2. Build dos Containers

```bash
# Usar script auxiliar
./scripts/slurm_container.sh

# Ou manualmente
docker build -t orchestration-backend:latest ./backend/
docker build -f ./backend/Dockerfile.slurm -t orchestration-slurm-worker:latest ./backend/
```

### 3. Configurar Docker Compose

Ajustar `docker-compose-development.yml` ou criar `docker-compose-production.yml`:

```yaml
  celery_slurm_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.slurm
    command: /slurm_worker_container.sh
    network_mode: "host"  # IMPORTANTE: Para acesso direto ao cluster
    env_file:
      - .env
      - .env.slurm  # ConfiguraÃ§Ãµes especÃ­ficas SLURM
    volumes:
      # Volumes do projeto
      - ./pipelines:/pipelines
      - ./datasets:/datasets
      - ./processes:/processes
      - ./logs:/var/log/orchestration
      
      # Volumes SLURM (CRÃTICO)
      - /etc/slurm:/etc/slurm:ro
      - /var/spool/slurm:/var/spool/slurm
      
      # Se usar autenticaÃ§Ã£o MUNGE
      - /etc/munge:/etc/munge:ro
      - /var/run/munge:/var/run/munge:ro
    
    depends_on:
      - rabbitmq
      - backend
```

### 4. Executar

```bash
# Apenas o worker SLURM
docker-compose -f docker-compose-development.yml up celery_slurm_worker

# Ou todo o stack
docker-compose -f docker-compose-development.yml up
```

## ğŸ”§ ConfiguraÃ§Ãµes de ProduÃ§Ã£o

### VariÃ¡veis de Ambiente (.env.slurm)

```bash
# Worker Configuration
WORKER_NAME=slurm
SLURM_WORKER_CONCURRENCY=4  # Ajustar conforme capacidade

# Logging
LOGGING_LEVEL=INFO
LOG_DIR=/var/log/orchestration

# SLURM especÃ­fico (se necessÃ¡rio)
SLURM_CONF=/etc/slurm/slurm.conf
SLURM_CLUSTER_NAME=production-cluster

# AutenticaÃ§Ã£o (se usar MUNGE)
# MUNGE_SOCKET=/var/run/munge/munge.socket.2
```

### Volumes e PermissÃµes

```bash
# No host, verificar permissÃµes
ls -la /etc/slurm/
ls -la /var/spool/slurm/

# Ajustar se necessÃ¡rio (cuidado em produÃ§Ã£o!)
sudo chown -R slurm:slurm /var/spool/slurm
sudo chmod 755 /var/spool/slurm
```

## ğŸ” VerificaÃ§Ã£o e Monitoramento

### Logs
```bash
# Logs do worker
docker-compose logs -f celery_slurm_worker

# Verificar conectividade SLURM
docker exec -it orchestration-celery_slurm_worker-1 sinfo
docker exec -it orchestration-celery_slurm_worker-1 squeue
```

### Testes de Conectividade
```bash
# Testar comandos SLURM
docker exec orchestration-celery_slurm_worker-1 bash -c "
  echo 'Testing SLURM connectivity...'
  sinfo -h && echo 'sinfo: OK' || echo 'sinfo: FAILED'
  squeue -h && echo 'squeue: OK' || echo 'squeue: FAILED'
"
```

### Health Check
```bash
# Verificar se worker estÃ¡ processando
docker exec orchestration-celery_slurm_worker-1 celery -A orchestration inspect active
```

## ğŸ› Troubleshooting

### Problemas Comuns

1. **"SLURM cluster not accessible"**
   - Verificar conectividade de rede
   - Verificar configuraÃ§Ã£o em `/etc/slurm/`
   - Verificar serviÃ§os SLURM no cluster

2. **Problemas de autenticaÃ§Ã£o**
   - Verificar MUNGE se usado
   - Verificar permissÃµes de usuÃ¡rio
   - Verificar volumes montados

3. **Worker nÃ£o conecta no RabbitMQ**
   - Verificar se RabbitMQ estÃ¡ rodando
   - Verificar variÃ¡veis RABBITMQ_* no .env

### Debug AvanÃ§ado

```bash
# Entrar no container para debug
docker exec -it orchestration-celery_slurm_worker-1 bash

# Dentro do container
conda activate orchestration
cd /app

# Testar manualmente
python manage.py shell
# >>> from core.executors.slurm.commands import *
# >>> sinfo()
```

## ğŸ“ˆ OtimizaÃ§Ãµes de ProduÃ§Ã£o

1. **ConcorrÃªncia**
   - Ajustar `SLURM_WORKER_CONCURRENCY` conforme carga esperada
   - Monitorar uso de CPU/memÃ³ria

2. **Logs**
   - RotaÃ§Ã£o de logs
   - CentralizaÃ§Ã£o (ELK, etc.)

3. **Monitoring**
   - Prometheus + Grafana para mÃ©tricas Celery
   - Alertas para falhas de conectividade SLURM

4. **Alta Disponibilidade**
   - MÃºltiplos workers SLURM
   - Load balancer se necessÃ¡rio

## ğŸ”„ AtualizaÃ§Ãµes

Para atualizar o worker SLURM:

```bash
# Rebuild
docker-compose build celery_slurm_worker

# Restart
docker-compose restart celery_slurm_worker
```

## ğŸ“ Suporte

Para problemas especÃ­ficos:
1. Verificar logs detalhados
2. Testar conectividade SLURM manualmente
3. Validar configuraÃ§Ãµes de rede
4. Verificar permissÃµes de usuÃ¡rio/volumes